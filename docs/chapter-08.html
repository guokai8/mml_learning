<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>chapter-08 â€“ Multimodal Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-969ddfa49e00a70eb3423444dbc81f6c.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1bebf2fac2c66d78ee8e4a0e5b34d43e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-56df71c9454ca07313afc907ff0d97f5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-1bebf2fac2c66d78ee8e4a0e5b34d43e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Multimodal Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./preface.html"> 
<span class="menu-text">Preface</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./how-to-use.html"> 
<span class="menu-text">How to Use</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chapters">    
        <li class="dropdown-header">Part I: Foundations</li>
        <li>
    <a class="dropdown-item" href="./chapter-01.html">
 <span class="dropdown-text">Chapter 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-02.html">
 <span class="dropdown-text">Chapter 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-03.html">
 <span class="dropdown-text">Chapter 3</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part II: Core Techniques</li>
        <li>
    <a class="dropdown-item" href="./chapter-04.html">
 <span class="dropdown-text">Chapter 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-05.html">
 <span class="dropdown-text">Chapter 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-06.html">
 <span class="dropdown-text">Chapter 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-07.html">
 <span class="dropdown-text">Chapter 7</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part III: Architectures</li>
        <li>
    <a class="dropdown-item" href="./chapter-08.html">
 <span class="dropdown-text">Chapter 8</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-09.html">
 <span class="dropdown-text">Chapter 9</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-10.html">
 <span class="dropdown-text">Chapter 10</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part IV: Practice</li>
        <li>
    <a class="dropdown-item" href="./chapter-11.html">
 <span class="dropdown-text">Chapter 11</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-12.html">
 <span class="dropdown-text">Chapter 12</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="./appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./README.md">
 <span class="dropdown-text">About</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/guokai8/mml_learning"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:guokai8@gmail.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-08.html">Part III: Architectures</a></li><li class="breadcrumb-item"><a href="./chapter-08.html">Chapter 8: Transformer Architecture</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">ğŸ“š Multimodal Learning: Theory, Practice, and Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how-to-use.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Use This Book</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Introduction to Multimodal Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Foundations and Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Feature Representation for Each Modality</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Core Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Feature Alignment and Bridging Modalities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Fusion Strategies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Attention Mechanisms in Multimodal Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 7: Contrastive Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-08.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Chapter 8: Transformer Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 9: Generative Models for Multimodal Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 10: Seminal Models and Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: Practice</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 11: Practical Implementation Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 12: Advanced Topics and Future Directions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comprehensive Appendix and Resources</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#chapter-8-transformer-architecture" id="toc-chapter-8-transformer-architecture" class="nav-link active" data-scroll-target="#chapter-8-transformer-architecture"><span class="header-section-number">1</span> Chapter 8: Transformer Architecture</a>
  <ul class="collapse">
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives"><span class="header-section-number">1.1</span> Learning Objectives</a></li>
  <li><a href="#the-problem-transformers-solve" id="toc-the-problem-transformers-solve" class="nav-link" data-scroll-target="#the-problem-transformers-solve"><span class="header-section-number">1.2</span> 8.1 The Problem Transformers Solve</a>
  <ul class="collapse">
  <li><a href="#limitations-of-sequential-models-rnns" id="toc-limitations-of-sequential-models-rnns" class="nav-link" data-scroll-target="#limitations-of-sequential-models-rnns"><span class="header-section-number">1.2.1</span> Limitations of Sequential Models (RNNs)</a></li>
  <li><a href="#cnn-limitations-for-sequences" id="toc-cnn-limitations-for-sequences" class="nav-link" data-scroll-target="#cnn-limitations-for-sequences"><span class="header-section-number">1.2.2</span> CNN Limitations for Sequences</a></li>
  <li><a href="#transformer-solution" id="toc-transformer-solution" class="nav-link" data-scroll-target="#transformer-solution"><span class="header-section-number">1.2.3</span> Transformer Solution</a></li>
  </ul></li>
  <li><a href="#self-attention-mechanism" id="toc-self-attention-mechanism" class="nav-link" data-scroll-target="#self-attention-mechanism"><span class="header-section-number">1.3</span> 8.2 Self-Attention Mechanism</a>
  <ul class="collapse">
  <li><a href="#intuition" id="toc-intuition" class="nav-link" data-scroll-target="#intuition"><span class="header-section-number">1.3.1</span> Intuition</a></li>
  <li><a href="#mathematical-definition" id="toc-mathematical-definition" class="nav-link" data-scroll-target="#mathematical-definition"><span class="header-section-number">1.3.2</span> Mathematical Definition</a></li>
  <li><a href="#numerical-example" id="toc-numerical-example" class="nav-link" data-scroll-target="#numerical-example"><span class="header-section-number">1.3.3</span> Numerical Example</a></li>
  <li><a href="#multi-head-attention" id="toc-multi-head-attention" class="nav-link" data-scroll-target="#multi-head-attention"><span class="header-section-number">1.3.4</span> Multi-Head Attention</a></li>
  <li><a href="#scaled-dot-product-attention-revisited" id="toc-scaled-dot-product-attention-revisited" class="nav-link" data-scroll-target="#scaled-dot-product-attention-revisited"><span class="header-section-number">1.3.5</span> Scaled Dot-Product Attention Revisited</a></li>
  </ul></li>
  <li><a href="#transformer-encoder" id="toc-transformer-encoder" class="nav-link" data-scroll-target="#transformer-encoder"><span class="header-section-number">1.4</span> 8.3 Transformer Encoder</a>
  <ul class="collapse">
  <li><a href="#architecture-overview" id="toc-architecture-overview" class="nav-link" data-scroll-target="#architecture-overview"><span class="header-section-number">1.4.1</span> Architecture Overview</a></li>
  <li><a href="#detailed-layer-breakdown" id="toc-detailed-layer-breakdown" class="nav-link" data-scroll-target="#detailed-layer-breakdown"><span class="header-section-number">1.4.2</span> Detailed Layer Breakdown</a></li>
  <li><a href="#full-transformer-encoder" id="toc-full-transformer-encoder" class="nav-link" data-scroll-target="#full-transformer-encoder"><span class="header-section-number">1.4.3</span> Full Transformer Encoder</a></li>
  </ul></li>
  <li><a href="#transformer-decoder" id="toc-transformer-decoder" class="nav-link" data-scroll-target="#transformer-decoder"><span class="header-section-number">1.5</span> 8.4 Transformer Decoder</a>
  <ul class="collapse">
  <li><a href="#causal-masking" id="toc-causal-masking" class="nav-link" data-scroll-target="#causal-masking"><span class="header-section-number">1.5.1</span> Causal Masking</a></li>
  <li><a href="#autoregressive-generation" id="toc-autoregressive-generation" class="nav-link" data-scroll-target="#autoregressive-generation"><span class="header-section-number">1.5.2</span> Autoregressive Generation</a></li>
  <li><a href="#cross-attention-in-decoder" id="toc-cross-attention-in-decoder" class="nav-link" data-scroll-target="#cross-attention-in-decoder"><span class="header-section-number">1.5.3</span> Cross-Attention in Decoder</a></li>
  </ul></li>
  <li><a href="#putting-it-together-vision-transformer-vit" id="toc-putting-it-together-vision-transformer-vit" class="nav-link" data-scroll-target="#putting-it-together-vision-transformer-vit"><span class="header-section-number">1.6</span> 8.5 Putting it Together: Vision Transformer (ViT)</a>
  <ul class="collapse">
  <li><a href="#architecture-for-images" id="toc-architecture-for-images" class="nav-link" data-scroll-target="#architecture-for-images"><span class="header-section-number">1.6.1</span> Architecture for Images</a></li>
  <li><a href="#why-vit-works" id="toc-why-vit-works" class="nav-link" data-scroll-target="#why-vit-works"><span class="header-section-number">1.6.2</span> Why ViT Works</a></li>
  </ul></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">1.7</span> Key Takeaways</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">1.8</span> Exercises</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-08.html">Part III: Architectures</a></li><li class="breadcrumb-item"><a href="./chapter-08.html">Chapter 8: Transformer Architecture</a></li></ol></nav></header>





<section id="chapter-8-transformer-architecture" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Chapter 8: Transformer Architecture</h1>
<hr>
<p><strong>Previous</strong>: <a href="./chapter-07.html">Chapter 7: Contrastive Learning</a> | <strong>Next</strong>: <a href="./chapter-09.html">Chapter 9: Generative Models for Multimodal Data</a> | <strong>Home</strong>: <a href="./index.html">Table of Contents</a></p>
<hr>
<section id="learning-objectives" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">1.1</span> Learning Objectives</h2>
<p>After reading this chapter, you should be able to: - Understand transformer fundamentals - Explain self-attention mechanism - Implement multi-head attention - Understand encoder-decoder architecture - Apply transformers to multimodal tasks</p>
</section>
<section id="the-problem-transformers-solve" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="the-problem-transformers-solve"><span class="header-section-number">1.2</span> 8.1 The Problem Transformers Solve</h2>
<section id="limitations-of-sequential-models-rnns" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="limitations-of-sequential-models-rnns"><span class="header-section-number">1.2.1</span> Limitations of Sequential Models (RNNs)</h3>
<p><strong>RNN limitations:</strong></p>
<pre><code>Processing sequence: w1, w2, w3, w4, w5

RNN forward pass (sequential):
  h0 = initialization
  h1 = RNN(w1, h0)  â† Must wait for h0
  h2 = RNN(w2, h1)  â† Must wait for h1
  h3 = RNN(w3, h2)  â† Must wait for h2
  h4 = RNN(w4, h3)  â† Must wait for h3
  h5 = RNN(w5, h4)  â† Must wait for h4

Problems:
â‘  Cannot parallelize
   Each step depends on previous
   Sequential bottleneck

â‘¡ Gradient flow issues
   Backprop through 5 steps:
   gradient = âˆ‚h5/âˆ‚h4 Ã— âˆ‚h4/âˆ‚h3 Ã— âˆ‚h3/âˆ‚h2 Ã— âˆ‚h2/âˆ‚h1 Ã— âˆ‚h1/âˆ‚h0

   Each factor typically &lt; 1:
   0.9^5 = 0.59  (50% loss)
   0.9^100 â‰ˆ 0   (vanishing gradient)

â‘¢ Limited context window
   Position t can see positions [0, t-1]
   Cannot look ahead (in some RNNs)
   Information degrades over long sequences</code></pre>
</section>
<section id="cnn-limitations-for-sequences" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="cnn-limitations-for-sequences"><span class="header-section-number">1.2.2</span> CNN Limitations for Sequences</h3>
<p><strong>CNN characteristics:</strong></p>
<pre><code>Local receptive field:
  3Ã—3 kernel sees 9 neighbors
  To see position distance 10:
  Need log(10) â‰ˆ 4 layers

  For long sequences:
  Need many layers
  Deep networks = hard to train</code></pre>
</section>
<section id="transformer-solution" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="transformer-solution"><span class="header-section-number">1.2.3</span> Transformer Solution</h3>
<p><strong>Key insight:</strong></p>
<pre><code>Why wait for sequential dependencies?

What if every position could see every other position simultaneously?

Query: Position i
Key/Value: All positions (including i)

Attention: Position i attends to all positions
Result: Global context immediately available!

Benefit:
â‘  Fully parallelizable
   All positions process simultaneously
   Each GPU core handles one position

â‘¡ No sequential bottleneck

â‘¢ Long-range dependencies captured immediately
   Position 0 can "see" position 100 in layer 1
   No need for deep networks</code></pre>
</section>
</section>
<section id="self-attention-mechanism" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="self-attention-mechanism"><span class="header-section-number">1.3</span> 8.2 Self-Attention Mechanism</h2>
<section id="intuition" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="intuition"><span class="header-section-number">1.3.1</span> Intuition</h3>
<p><strong>Example - Machine translation:</strong></p>
<pre><code>English: "The animal didn't cross the street because it was too tired"

Ambiguity: What does "it" refer to?
  Option A: "animal" (correct)
  Option B: "street" (incorrect)

How humans understand:
  Focus on "it" (pronoun)
  Look back at possible referents: "animal", "street"
  "Animal" makes more sense in context
  â†’ "it" = "animal"

Self-attention for "it":
  Query: "it"
  Key/Value options: ["The", "animal", "didn't", ..., "tired"]
  Attention: Which words help interpret "it"?
    "animal": High attention (antecedent)
    "cross": Medium attention (related event)
    "The": Low attention (not informative)
  Result: "it" representation influenced mainly by "animal"</code></pre>
</section>
<section id="mathematical-definition" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="mathematical-definition"><span class="header-section-number">1.3.2</span> Mathematical Definition</h3>
<p><strong>Components:</strong></p>
<pre><code>Query (Q): What am I asking about?
Key (K): What information is available?
Value (V): What to retrieve?

Analogy - Database:
  Query: Search terms ("animal")
  Keys: Database field names and values
  Values: Data to retrieve

Example:
  Query: "hungry"
  Key matches: "starving" (high similarity), "tired" (medium)
  Values: Corresponding word embeddings
  Result: Weighted sum of values based on key similarity to query</code></pre>
<p><strong>Formula:</strong></p>
<pre><code>Attention(Q, K, V) = softmax(Q @ K^T / âˆšd_k) @ V

Breakdown:

Q @ K^T:
  Query dot Key
  Shape: (seq_len, seq_len)
  Result: similarity matrix
  Element [i,j] = how much query_i matches key_j

  / âˆšd_k:
  Normalization by embedding dimension
  Prevents gradient explosion

softmax(...):
  Convert similarities to probabilities [0,1]
  Sum to 1 per row
  Interpretation: How much to "pay attention" to each position

@ V:
  Weight values by attention weights
  Result: Weighted combination of value vectors
  Each query gets context-specific value</code></pre>
</section>
<section id="numerical-example" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="numerical-example"><span class="header-section-number">1.3.3</span> Numerical Example</h3>
<p><strong>Setup:</strong></p>
<pre><code>Sequence: ["The", "cat", "sat"]
Embedding dimension: d_k = 4

Query vectors:
  Q1 = [0.1, 0.2, 0.3, 0.1]  for "The"
  Q2 = [0.4, 0.1, 0.2, 0.3]  for "cat"
  Q3 = [0.2, 0.3, 0.1, 0.4]  for "sat"

Key vectors (same as query in self-attention):
  K1 = [0.1, 0.2, 0.3, 0.1]  for "The"
  K2 = [0.4, 0.1, 0.2, 0.3]  for "cat"
  K3 = [0.2, 0.3, 0.1, 0.4]  for "sat"

Value vectors:
  V1 = [1, 0, 0, 0]  for "The"
  V2 = [0, 1, 0, 0]  for "cat"
  V3 = [0, 0, 1, 0]  for "sat"</code></pre>
<p><strong>Computation for first query (position 0: â€œTheâ€):</strong></p>
<pre><code>Step 1: Q1 @ K^T (similarity scores)
  Q1Â·K1 = 0.1*0.1 + 0.2*0.2 + 0.3*0.3 + 0.1*0.1 = 0.15
  Q1Â·K2 = 0.1*0.4 + 0.2*0.1 + 0.3*0.2 + 0.1*0.3 = 0.15
  Q1Â·K3 = 0.1*0.2 + 0.2*0.3 + 0.3*0.1 + 0.1*0.4 = 0.15

  Scores: [0.15, 0.15, 0.15]  (all equal - new in training)

Step 2: Divide by âˆšd_k = âˆš4 = 2
  [0.075, 0.075, 0.075]

Step 3: Softmax
  exp(0.075) â‰ˆ 1.078
  exp(0.075) â‰ˆ 1.078
  exp(0.075) â‰ˆ 1.078

  Sum: 3.234

  Softmax: [1.078/3.234, 1.078/3.234, 1.078/3.234]
         = [0.333, 0.333, 0.333]
         (uniform distribution)

Step 4: Weight values
  0.333 * V1 + 0.333 * V2 + 0.333 * V3
  = 0.333 * [1,0,0,0] + 0.333 * [0,1,0,0] + 0.333 * [0,0,1,0]
  = [0.333, 0.333, 0.333, 0]</code></pre>
<p><strong>After training:</strong></p>
<pre><code>With learned embeddings, differences emerge:

Step 1: Q1 @ K^T
  Q1Â·K1 = 0.8   (high - "The" attends to itself)
  Q1Â·K2 = 0.2   (low - "The" doesn't attend to "cat")
  Q1Â·K3 = 0.3   (low - "The" doesn't attend to "sat")

Step 2: After scaling and softmax
  [0.7, 0.15, 0.15]

Step 3: Weighted values
  0.7 * V1 + 0.15 * V2 + 0.15 * V3
  = [0.7, 0.15, 0.15, 0]

  Interpretation:
  "The" mostly looks at itself
  Some information from neighboring words
  Reasonable: "The" is article, not much context needed</code></pre>
</section>
<section id="multi-head-attention" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="multi-head-attention"><span class="header-section-number">1.3.4</span> Multi-Head Attention</h3>
<p><strong>Why multiple heads?</strong></p>
<pre><code>Single attention head learns one type of relationship
Different heads can learn different patterns

Head 1: Syntactic (grammar)
  "verb" attends to "object"
  "noun" attends to "adjective"

Head 2: Semantic (meaning)
  "pronoun" attends to "antecedent"
  "reference" attends to "entity"

Head 3: Long-range
  "end of sentence" attends to "beginning"
  Captures discourse structure

Head 4: Word type
  Different parts of speech have different patterns

Multiple heads = multiple representation subspaces
More expressive than single head</code></pre>
<p><strong>Architecture:</strong></p>
<pre><code>Input: x (seq_len, d_model)

For each head h = 1 to num_heads:
  â‘  Project to query space
     Q_h = x @ W_q^(h)    (seq_len, d_k)

  â‘¡ Project to key space
     K_h = x @ W_k^(h)    (seq_len, d_k)

  â‘¢ Project to value space
     V_h = x @ W_v^(h)    (seq_len, d_v)

  â‘£ Compute attention
     head_h = Attention(Q_h, K_h, V_h)  (seq_len, d_v)

Concatenate all heads:
  MultiHead = [head_1 || head_2 || ... || head_h]
              (seq_len, h*d_v)

Linear projection:
  output = MultiHead @ W_o
           (seq_len, d_model)</code></pre>
<p><strong>Example - 8 heads with d_model=512:</strong></p>
<pre><code>Each head operates in d_k = 512/8 = 64 dimensional space
8 different projection matrices per Q, K, V

Result:
  8 independent attention mechanisms
  Each learns different patterns
  Combined through concatenation and final projection

Total parameters for multi-head attention:
  Q projections: 8 Ã— 512 Ã— 64 = 262K
  K projections: 8 Ã— 512 Ã— 64 = 262K
  V projections: 8 Ã— 512 Ã— 64 = 262K
  Output projection: 512 Ã— 512 = 262K
  Total: ~1M parameters per multi-head attention layer</code></pre>
</section>
<section id="scaled-dot-product-attention-revisited" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="scaled-dot-product-attention-revisited"><span class="header-section-number">1.3.5</span> Scaled Dot-Product Attention Revisited</h3>
<p><strong>Why scale by 1/âˆšd_k?</strong></p>
<pre><code>Reason: Prevents gradient vanishing

Without scaling:
  For large d_k:
  Q @ K^T values become very large

  Example: Q and K each 64D
  Dot product: 64 independent terms
  Average value: 64 * (avg term)

  Large values â†’ softmax saturates â†’ gradients â†’ 0

Scaling by 1/âˆšd_k:
  Normalizes dot product variance
  Keep values in reasonable range [-1, 1] roughly
  Softmax doesn't saturate
  Gradients flow properly

Mathematical justification:
  Var(Q @ K^T) = Var(Î£ q_i * k_i)
                = Î£ Var(q_i * k_i)
                = d_k  (if independent)

  Std dev = âˆšd_k

  Scaling by 1/âˆšd_k makes std dev = 1
  Keeps gradients stable</code></pre>
</section>
</section>
<section id="transformer-encoder" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="transformer-encoder"><span class="header-section-number">1.4</span> 8.3 Transformer Encoder</h2>
<section id="architecture-overview" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="architecture-overview"><span class="header-section-number">1.4.1</span> Architecture Overview</h3>
<pre><code>Input sequence
    â†“
Embedding + Positional Encoding
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Transformer Encoder Layer  â”‚ Ã—N (typically 12)
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Multi-Head Attention   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â†“                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Add &amp; Normalize         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â†“                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Feed-Forward Network    â”‚ â”‚
â”‚  â”‚ (2 linear layers, ReLU) â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â†“                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Add &amp; Normalize         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
Output (same shape as input)</code></pre>
</section>
<section id="detailed-layer-breakdown" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="detailed-layer-breakdown"><span class="header-section-number">1.4.2</span> Detailed Layer Breakdown</h3>
<p><strong>1. Positional Encoding</strong></p>
<pre><code>Problem: Self-attention is permutation invariant
  Meaning: Word order doesn't matter!

  Attention doesn't care about position
  Just about content similarity

  Example:
    "dog bites man" vs "man bites dog"
    Same words, different meaning
    But attention treats them the same!

Solution: Add position information

Sinusoidal encoding:
  PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
  PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))

  Where:
    pos = position in sequence (0, 1, 2, ...)
    i = dimension index (0, 1, 2, ..., d_model/2)

Example: Position 0, dimension 0
  PE(0, 0) = sin(0) = 0

  Position 1, dimension 0:
  PE(1, 0) = sin(1 / 10000^0) = sin(1) â‰ˆ 0.84

Properties:
  â‘  Different positions have different encodings
  â‘¡ Patterns repeat at different frequencies
  â‘¢ Model can learn relative positions
  â‘£ Can extrapolate to longer sequences than training</code></pre>
<p><strong>2. Multi-Head Self-Attention</strong></p>
<pre><code>All positions attend to all positions
8-12 heads typically
Each head learns different patterns

Output same shape as input</code></pre>
<p><strong>3. Add &amp; Normalize (Residual Connection + Layer Normalization)</strong></p>
<pre><code>Residual connection:
  output = attention_output + input

  Why?
  â‘  Preserves original information
  â‘¡ Enables deep networks (gradient flows directly)
  â‘¢ Output can learn "residual" (difference)

Layer Normalization:
  Normalize across feature dimension

  mean = mean(x along d_model dimension)
  variance = var(x along d_model dimension)
  normalized = (x - mean) / sqrt(variance + epsilon)
  output = Î³ * normalized + Î²

  Î³, Î² are learnable parameters

  Why LN instead of Batch Norm?
  â‘  Batch norm depends on batch statistics
     Different at train/test time

  â‘¡ Layer norm is deterministic
     Doesn't depend on batch
     Same at train/test

  â‘¢ Works better for sequences</code></pre>
<p><strong>4. Feed-Forward Network</strong></p>
<pre><code>MLP with 2 layers and ReLU:

FFN(x) = Linear2(ReLU(Linear1(x)))

Dimensions:
  Linear1: d_model â†’ d_ff (usually 4*d_model)
  ReLU: d_ff â†’ d_ff
  Linear2: d_ff â†’ d_model

Example with d_model = 512:
  Linear1: 512 â†’ 2048
  ReLU: 2048 â†’ 2048
  Linear2: 2048 â†’ 512

Why expand then contract?
  â‘  Increases non-linearity
  â‘¡ More expressive intermediate representation
  â‘¢ Standard in deep learning</code></pre>
</section>
<section id="full-transformer-encoder" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="full-transformer-encoder"><span class="header-section-number">1.4.3</span> Full Transformer Encoder</h3>
<p><strong>BERT (Bidirectional Encoder Representations from Transformers):</strong></p>
<pre><code>Architecture:
  â‘  Input: Tokens or subword units

  â‘¡ Embeddings:
     - Token embedding (word id â†’ vector)
     - Positional embedding (position â†’ vector)
     - Segment embedding (which sentence)
     - Sum all three

  â‘¢ 12 layers (BERT-base) or 24 (BERT-large) of:
     - Multi-head attention (8-12 heads)
     - Feed-forward network
     - Residual connections + Layer norm

  â‘£ Output: Contextual embedding for each token

Example input: "The cat sat on the mat"

Processing:
  [CLS] The cat sat on the mat [SEP]
    â†“
  Embed each token
    â†“
  Add positional info
    â†“
  Layer 1:
    All tokens attend to all tokens
    Self-attention with 12 different heads

    "The" attends to: "The" (self), "cat", "sat", "on", "the", "mat"
    Different heads pay attention to different words
    Results concatenated

    Feed-forward applied to each position
    Residual + Layer norm

  Layer 2-12:
    Same process, but input is output from previous layer
    Further refinement

Output:
  12 vectors for each token
  Plus one special [CLS] token representing full sequence</code></pre>
</section>
</section>
<section id="transformer-decoder" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="transformer-decoder"><span class="header-section-number">1.5</span> 8.4 Transformer Decoder</h2>
<section id="causal-masking" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="causal-masking"><span class="header-section-number">1.5.1</span> Causal Masking</h3>
<p><strong>Problem:</strong></p>
<pre><code>During inference, generate one token at a time:
  Step 1: Predict token 1 (no prior tokens)
  Step 2: Predict token 2 (given token 1)
  Step 3: Predict token 3 (given tokens 1, 2)

During training (teacher forcing):
  Complete sequence available: token 1, 2, 3, 4, 5

To prepare model for inference:
  Hide future tokens during training

Mechanism: Causal mask</code></pre>
<p><strong>Causal mask visualization:</strong></p>
<pre><code>Attention positions (what can attend to what):

Sequence: [token_1, token_2, token_3, token_4, token_5]

Position 1 (token_1):
  Can attend to: position 1
  Cannot attend to: positions 2, 3, 4, 5

Position 2 (token_2):
  Can attend to: positions 1, 2
  Cannot attend to: positions 3, 4, 5

Position 3 (token_3):
  Can attend to: positions 1, 2, 3
  Cannot attend to: positions 4, 5

Attention matrix (âœ“ = can attend, âœ— = masked):

       pos1  pos2  pos3  pos4  pos5
pos1    âœ“     âœ—     âœ—     âœ—     âœ—
pos2    âœ“     âœ“     âœ—     âœ—     âœ—
pos3    âœ“     âœ“     âœ“     âœ—     âœ—
pos4    âœ“     âœ“     âœ“     âœ“     âœ—
pos5    âœ“     âœ“     âœ“     âœ“     âœ“

Mask implementation:
  Before softmax, set masked positions to -âˆ
  softmax(-âˆ) = 0
  Effect: Attention weight = 0 for masked positions</code></pre>
</section>
<section id="autoregressive-generation" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="autoregressive-generation"><span class="header-section-number">1.5.2</span> Autoregressive Generation</h3>
<p><strong>Process:</strong></p>
<pre><code>â‘  Start: Input special token [START]
         Decoder produces distribution over vocabulary

â‘¡ Step 1: Sample/select token with highest probability
          Let's say we get "A"

â‘¢ Step 2: Input "[START] A"
          Decoder predicts next token
          Get "red"

â‘£ Step 3: Input "[START] A red"
          Decoder predicts next token
          Get "cat"

â‘¤ Continue until [END] token or max length

Generated: "A red cat"</code></pre>
<p><strong>Key points:</strong></p>
<pre><code>â‘  Causal masking ensures only past tokens visible
â‘¡ Gradual refinement of representation
â‘¢ Can use greedy (highest probability) or sampling
â‘£ Sampling: More diverse but less controlled
   Greedy: More consistent but can repeat</code></pre>
</section>
<section id="cross-attention-in-decoder" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="cross-attention-in-decoder"><span class="header-section-number">1.5.3</span> Cross-Attention in Decoder</h3>
<p><strong>Integration with encoder:</strong></p>
<pre><code>Encoder processes source:
  e.g., Image encoded to 196 patch embeddings

Decoder:
  â‘  Self-attention: Decoder attends to previously generated tokens
  â‘¡ Cross-attention: Decoder attends to encoder output
  â‘¢ Feed-forward

Cross-attention details:
  Query: Current decoder hidden state
  Key/Value: Encoder output

  Result: Decoder can look at source modality
          Ground generation in input</code></pre>
<p><strong>Example - Image captioning:</strong></p>
<pre><code>Image: [Cat photo]
       â†“
Image encoder: 196 patch embeddings

Decoder generating caption:

Step 1:
  Decoder input: [START]
  Self-attention: Only [START], attends to itself
  Cross-attention: [START] attends to all 196 patches
                   "What's in image?"
  Output: Probability distribution for first word

Step 2:
  Decoder input: [START] A
  Self-attention: "A" attends to [START] and itself
                  "What context?"
  Cross-attention: "A" attends to patches
                   "What modifies 'A'?"
  Output: "cat"

Step 3:
  Decoder input: [START] A cat
  Self-attention: "cat" attends to [START], "A", "cat"
  Cross-attention: "cat" attends to patches
                   "What object is this?"
  Output: "sitting"

...

Caption: "A cat sitting on a couch"</code></pre>
</section>
</section>
<section id="putting-it-together-vision-transformer-vit" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="putting-it-together-vision-transformer-vit"><span class="header-section-number">1.6</span> 8.5 Putting it Together: Vision Transformer (ViT)</h2>
<section id="architecture-for-images" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="architecture-for-images"><span class="header-section-number">1.6.1</span> Architecture for Images</h3>
<pre><code>Image (224Ã—224Ã—3)
    â†“
Divide into patches (16Ã—16)
    â†“
14 Ã— 14 = 196 patches
    â†“
Each patch: 16Ã—16Ã—3 = 768D
    â†“
Linear projection: 768D â†’ 768D embedding
    â†“
Add [CLS] special token
    â†“
Positional encoding (196 + 1 positions)
    â†“
Concatenate: [[CLS]; patch_1; patch_2; ...; patch_196]
             (197 tokens of 768D each)
    â†“
Transformer encoder (12 layers):
  Multi-head attention (12 heads)
  Feed-forward (3072D intermediate)
  Residual connections + Layer norm
    â†“
Extract [CLS] token representation
    â†“
Linear classifier: 768D â†’ num_classes
    â†“
Output: Class probabilities</code></pre>
</section>
<section id="why-vit-works" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="why-vit-works"><span class="header-section-number">1.6.2</span> Why ViT Works</h3>
<pre><code>Key insight 1: Patches as tokens
  Images have spatial structure
  Patches preserve local information
  Transformer learns global relationships

Key insight 2: Transformer is universal
  Can process any sequence of tokens
  Doesn't care if tokens are image or text
  Same architecture works for both!

Key insight 3: Attention gives global context
  CNNs need many layers for global receptive field
  ViT has global attention from layer 1
  Enables fast learning

Empirical finding:
  With small data: CNN &gt;&gt; ViT
  With large data: ViT &gt;&gt; CNN

  Trade-off: Inductive bias vs expressive power
  CNN: Strong inductive bias (local structure)
       Works with limited data
  ViT: Weak inductive bias
       Needs large data to learn structure</code></pre>
</section>
</section>
<section id="key-takeaways" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="key-takeaways"><span class="header-section-number">1.7</span> Key Takeaways</h2>
<ul>
<li><strong>Transformers</strong> solve sequential bottleneck through attention</li>
<li><strong>Self-attention</strong> computes context through similarity</li>
<li><strong>Multi-head attention</strong> learns diverse patterns</li>
<li><strong>Positional encoding</strong> preserves sequence order</li>
<li><strong>Residual connections</strong> enable deep networks</li>
<li><strong>Feed-forward networks</strong> add non-linearity</li>
<li><strong>Causal masking</strong> enables autoregressive generation</li>
<li><strong>Cross-attention</strong> connects source and target</li>
<li><strong>Vision Transformer</strong> shows transformers work for images too</li>
</ul>
</section>
<section id="exercises" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="exercises"><span class="header-section-number">1.8</span> Exercises</h2>
<p><strong>â­ Beginner:</strong> 1. Compute self-attention by hand 2. Understand causal masking 3. Visualize positional encoding patterns</p>
<p><strong>â­â­ Intermediate:</strong> 4. Implement multi-head attention from scratch 5. Build simple transformer encoder 6. Visualize attention patterns</p>
<p><strong>â­â­â­ Advanced:</strong> 7. Implement full transformer encoder-decoder 8. Build Vision Transformer 9. Implement efficient attention variants</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Â© 2024 Kai Guo - Multimodal Learning Guide</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>