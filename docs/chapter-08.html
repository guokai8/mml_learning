<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>chapter-08 – Multimodal Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark-969ddfa49e00a70eb3423444dbc81f6c.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-065a5179aebd64318d7ea99d77b64a9e.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1bebf2fac2c66d78ee8e4a0e5b34d43e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark-56df71c9454ca07313afc907ff0d97f5.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="site_libs/bootstrap/bootstrap-1bebf2fac2c66d78ee8e4a0e5b34d43e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar docked nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="./index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Multimodal Learning</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="./index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./preface.html"> 
<span class="menu-text">Preface</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./how-to-use.html"> 
<span class="menu-text">How to Use</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-chapters" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Chapters</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-chapters">    
        <li class="dropdown-header">Part I: Foundations</li>
        <li>
    <a class="dropdown-item" href="./chapter-01.html">
 <span class="dropdown-text">Chapter 1</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-02.html">
 <span class="dropdown-text">Chapter 2</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-03.html">
 <span class="dropdown-text">Chapter 3</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part II: Core Techniques</li>
        <li>
    <a class="dropdown-item" href="./chapter-04.html">
 <span class="dropdown-text">Chapter 4</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-05.html">
 <span class="dropdown-text">Chapter 5</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-06.html">
 <span class="dropdown-text">Chapter 6</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-07.html">
 <span class="dropdown-text">Chapter 7</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part III: Architectures</li>
        <li>
    <a class="dropdown-item" href="./chapter-08.html">
 <span class="dropdown-text">Chapter 8</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-09.html">
 <span class="dropdown-text">Chapter 9</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-10.html">
 <span class="dropdown-text">Chapter 10</span></a>
  </li>  
        <li><hr class="dropdown-divider"></li>
        <li class="dropdown-header">Part IV: Practice</li>
        <li>
    <a class="dropdown-item" href="./chapter-11.html">
 <span class="dropdown-text">Chapter 11</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./chapter-12.html">
 <span class="dropdown-text">Chapter 12</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="./appendix.html">
 <span class="dropdown-text">Appendix</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="./README.md">
 <span class="dropdown-text">About</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/guokai8/mml_learning"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:guokai8@gmail.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-08.html">Part III: Architectures</a></li><li class="breadcrumb-item"><a href="./chapter-08.html">Chapter 8: Transformer Architecture</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Getting Started</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">📚 Multimodal Learning: Theory, Practice, and Applications</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./preface.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./how-to-use.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">How to Use This Book</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">Part I: Foundations</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-01.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 1: Introduction to Multimodal Learning</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-02.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 2: Foundations and Core Concepts</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-03.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 3: Feature Representation for Each Modality</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Part II: Core Techniques</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-04.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 4: Feature Alignment and Bridging Modalities</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-05.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 5: Fusion Strategies</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-06.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 6: Attention Mechanisms in Multimodal Systems</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-07.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 7: Contrastive Learning</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true">
 <span class="menu-text">Part III: Architectures</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-08.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Chapter 8: Transformer Architecture</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-09.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 9: Generative Models for Multimodal Data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 10: Seminal Models and Architectures</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true">
 <span class="menu-text">Part IV: Practice</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 11: Practical Implementation Guide</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter-12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Chapter 12: Advanced Topics and Future Directions</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true">
 <span class="menu-text">Resources</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appendix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Comprehensive Appendix and Resources</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#chapter-8-transformer-architecture" id="toc-chapter-8-transformer-architecture" class="nav-link active" data-scroll-target="#chapter-8-transformer-architecture"><span class="header-section-number">1</span> Chapter 8: Transformer Architecture</a>
  <ul class="collapse">
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link" data-scroll-target="#learning-objectives"><span class="header-section-number">1.1</span> Learning Objectives</a></li>
  <li><a href="#the-problem-transformers-solve" id="toc-the-problem-transformers-solve" class="nav-link" data-scroll-target="#the-problem-transformers-solve"><span class="header-section-number">1.2</span> 8.1 The Problem Transformers Solve</a>
  <ul class="collapse">
  <li><a href="#limitations-of-sequential-models-rnns" id="toc-limitations-of-sequential-models-rnns" class="nav-link" data-scroll-target="#limitations-of-sequential-models-rnns"><span class="header-section-number">1.2.1</span> Limitations of Sequential Models (RNNs)</a></li>
  <li><a href="#cnn-limitations-for-sequences" id="toc-cnn-limitations-for-sequences" class="nav-link" data-scroll-target="#cnn-limitations-for-sequences"><span class="header-section-number">1.2.2</span> CNN Limitations for Sequences</a></li>
  <li><a href="#transformer-solution" id="toc-transformer-solution" class="nav-link" data-scroll-target="#transformer-solution"><span class="header-section-number">1.2.3</span> Transformer Solution</a></li>
  </ul></li>
  <li><a href="#self-attention-mechanism" id="toc-self-attention-mechanism" class="nav-link" data-scroll-target="#self-attention-mechanism"><span class="header-section-number">1.3</span> 8.2 Self-Attention Mechanism</a>
  <ul class="collapse">
  <li><a href="#intuition" id="toc-intuition" class="nav-link" data-scroll-target="#intuition"><span class="header-section-number">1.3.1</span> Intuition</a></li>
  <li><a href="#mathematical-definition" id="toc-mathematical-definition" class="nav-link" data-scroll-target="#mathematical-definition"><span class="header-section-number">1.3.2</span> Mathematical Definition</a></li>
  <li><a href="#numerical-example" id="toc-numerical-example" class="nav-link" data-scroll-target="#numerical-example"><span class="header-section-number">1.3.3</span> Numerical Example</a></li>
  <li><a href="#multi-head-attention" id="toc-multi-head-attention" class="nav-link" data-scroll-target="#multi-head-attention"><span class="header-section-number">1.3.4</span> Multi-Head Attention</a></li>
  <li><a href="#scaled-dot-product-attention-revisited" id="toc-scaled-dot-product-attention-revisited" class="nav-link" data-scroll-target="#scaled-dot-product-attention-revisited"><span class="header-section-number">1.3.5</span> Scaled Dot-Product Attention Revisited</a></li>
  </ul></li>
  <li><a href="#transformer-encoder" id="toc-transformer-encoder" class="nav-link" data-scroll-target="#transformer-encoder"><span class="header-section-number">1.4</span> 8.3 Transformer Encoder</a>
  <ul class="collapse">
  <li><a href="#architecture-overview" id="toc-architecture-overview" class="nav-link" data-scroll-target="#architecture-overview"><span class="header-section-number">1.4.1</span> Architecture Overview</a></li>
  <li><a href="#detailed-layer-breakdown" id="toc-detailed-layer-breakdown" class="nav-link" data-scroll-target="#detailed-layer-breakdown"><span class="header-section-number">1.4.2</span> Detailed Layer Breakdown</a></li>
  <li><a href="#full-transformer-encoder" id="toc-full-transformer-encoder" class="nav-link" data-scroll-target="#full-transformer-encoder"><span class="header-section-number">1.4.3</span> Full Transformer Encoder</a></li>
  </ul></li>
  <li><a href="#transformer-decoder" id="toc-transformer-decoder" class="nav-link" data-scroll-target="#transformer-decoder"><span class="header-section-number">1.5</span> 8.4 Transformer Decoder</a>
  <ul class="collapse">
  <li><a href="#causal-masking" id="toc-causal-masking" class="nav-link" data-scroll-target="#causal-masking"><span class="header-section-number">1.5.1</span> Causal Masking</a></li>
  <li><a href="#autoregressive-generation" id="toc-autoregressive-generation" class="nav-link" data-scroll-target="#autoregressive-generation"><span class="header-section-number">1.5.2</span> Autoregressive Generation</a></li>
  <li><a href="#cross-attention-in-decoder" id="toc-cross-attention-in-decoder" class="nav-link" data-scroll-target="#cross-attention-in-decoder"><span class="header-section-number">1.5.3</span> Cross-Attention in Decoder</a></li>
  </ul></li>
  <li><a href="#putting-it-together-vision-transformer-vit" id="toc-putting-it-together-vision-transformer-vit" class="nav-link" data-scroll-target="#putting-it-together-vision-transformer-vit"><span class="header-section-number">1.6</span> 8.5 Putting it Together: Vision Transformer (ViT)</a>
  <ul class="collapse">
  <li><a href="#architecture-for-images" id="toc-architecture-for-images" class="nav-link" data-scroll-target="#architecture-for-images"><span class="header-section-number">1.6.1</span> Architecture for Images</a></li>
  <li><a href="#why-vit-works" id="toc-why-vit-works" class="nav-link" data-scroll-target="#why-vit-works"><span class="header-section-number">1.6.2</span> Why ViT Works</a></li>
  </ul></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">1.7</span> Key Takeaways</a></li>
  <li><a href="#exercises" id="toc-exercises" class="nav-link" data-scroll-target="#exercises"><span class="header-section-number">1.8</span> Exercises</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter-08.html">Part III: Architectures</a></li><li class="breadcrumb-item"><a href="./chapter-08.html">Chapter 8: Transformer Architecture</a></li></ol></nav></header>





<section id="chapter-8-transformer-architecture" class="level1" data-number="1">
<h1 data-number="1"><span class="header-section-number">1</span> Chapter 8: Transformer Architecture</h1>
<hr>
<p><strong>Previous</strong>: <a href="./chapter-07.html">Chapter 7: Contrastive Learning</a> | <strong>Next</strong>: <a href="./chapter-09.html">Chapter 9: Generative Models for Multimodal Data</a> | <strong>Home</strong>: <a href="./index.html">Table of Contents</a></p>
<hr>
<section id="learning-objectives" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">1.1</span> Learning Objectives</h2>
<p>After reading this chapter, you should be able to: - Understand transformer fundamentals - Explain self-attention mechanism - Implement multi-head attention - Understand encoder-decoder architecture - Apply transformers to multimodal tasks</p>
</section>
<section id="the-problem-transformers-solve" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="the-problem-transformers-solve"><span class="header-section-number">1.2</span> 8.1 The Problem Transformers Solve</h2>
<section id="limitations-of-sequential-models-rnns" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="limitations-of-sequential-models-rnns"><span class="header-section-number">1.2.1</span> Limitations of Sequential Models (RNNs)</h3>
<p><strong>RNN limitations:</strong></p>
<pre><code>Processing sequence: w1, w2, w3, w4, w5

RNN forward pass (sequential):
  h0 = initialization
  h1 = RNN(w1, h0)  ← Must wait for h0
  h2 = RNN(w2, h1)  ← Must wait for h1
  h3 = RNN(w3, h2)  ← Must wait for h2
  h4 = RNN(w4, h3)  ← Must wait for h3
  h5 = RNN(w5, h4)  ← Must wait for h4

Problems:
① Cannot parallelize
   Each step depends on previous
   Sequential bottleneck

② Gradient flow issues
   Backprop through 5 steps:
   gradient = ∂h5/∂h4 × ∂h4/∂h3 × ∂h3/∂h2 × ∂h2/∂h1 × ∂h1/∂h0

   Each factor typically &lt; 1:
   0.9^5 = 0.59  (50% loss)
   0.9^100 ≈ 0   (vanishing gradient)

③ Limited context window
   Position t can see positions [0, t-1]
   Cannot look ahead (in some RNNs)
   Information degrades over long sequences</code></pre>
</section>
<section id="cnn-limitations-for-sequences" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="cnn-limitations-for-sequences"><span class="header-section-number">1.2.2</span> CNN Limitations for Sequences</h3>
<p><strong>CNN characteristics:</strong></p>
<pre><code>Local receptive field:
  3×3 kernel sees 9 neighbors
  To see position distance 10:
  Need log(10) ≈ 4 layers

  For long sequences:
  Need many layers
  Deep networks = hard to train</code></pre>
</section>
<section id="transformer-solution" class="level3" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="transformer-solution"><span class="header-section-number">1.2.3</span> Transformer Solution</h3>
<p><strong>Key insight:</strong></p>
<pre><code>Why wait for sequential dependencies?

What if every position could see every other position simultaneously?

Query: Position i
Key/Value: All positions (including i)

Attention: Position i attends to all positions
Result: Global context immediately available!

Benefit:
① Fully parallelizable
   All positions process simultaneously
   Each GPU core handles one position

② No sequential bottleneck

③ Long-range dependencies captured immediately
   Position 0 can "see" position 100 in layer 1
   No need for deep networks</code></pre>
</section>
</section>
<section id="self-attention-mechanism" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="self-attention-mechanism"><span class="header-section-number">1.3</span> 8.2 Self-Attention Mechanism</h2>
<section id="intuition" class="level3" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="intuition"><span class="header-section-number">1.3.1</span> Intuition</h3>
<p><strong>Example - Machine translation:</strong></p>
<pre><code>English: "The animal didn't cross the street because it was too tired"

Ambiguity: What does "it" refer to?
  Option A: "animal" (correct)
  Option B: "street" (incorrect)

How humans understand:
  Focus on "it" (pronoun)
  Look back at possible referents: "animal", "street"
  "Animal" makes more sense in context
  → "it" = "animal"

Self-attention for "it":
  Query: "it"
  Key/Value options: ["The", "animal", "didn't", ..., "tired"]
  Attention: Which words help interpret "it"?
    "animal": High attention (antecedent)
    "cross": Medium attention (related event)
    "The": Low attention (not informative)
  Result: "it" representation influenced mainly by "animal"</code></pre>
</section>
<section id="mathematical-definition" class="level3" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="mathematical-definition"><span class="header-section-number">1.3.2</span> Mathematical Definition</h3>
<p><strong>Components:</strong></p>
<pre><code>Query (Q): What am I asking about?
Key (K): What information is available?
Value (V): What to retrieve?

Analogy - Database:
  Query: Search terms ("animal")
  Keys: Database field names and values
  Values: Data to retrieve

Example:
  Query: "hungry"
  Key matches: "starving" (high similarity), "tired" (medium)
  Values: Corresponding word embeddings
  Result: Weighted sum of values based on key similarity to query</code></pre>
<p><strong>Formula:</strong></p>
<pre><code>Attention(Q, K, V) = softmax(Q @ K^T / √d_k) @ V

Breakdown:

Q @ K^T:
  Query dot Key
  Shape: (seq_len, seq_len)
  Result: similarity matrix
  Element [i,j] = how much query_i matches key_j

  / √d_k:
  Normalization by embedding dimension
  Prevents gradient explosion

softmax(...):
  Convert similarities to probabilities [0,1]
  Sum to 1 per row
  Interpretation: How much to "pay attention" to each position

@ V:
  Weight values by attention weights
  Result: Weighted combination of value vectors
  Each query gets context-specific value</code></pre>
</section>
<section id="numerical-example" class="level3" data-number="1.3.3">
<h3 data-number="1.3.3" class="anchored" data-anchor-id="numerical-example"><span class="header-section-number">1.3.3</span> Numerical Example</h3>
<p><strong>Setup:</strong></p>
<pre><code>Sequence: ["The", "cat", "sat"]
Embedding dimension: d_k = 4

Query vectors:
  Q1 = [0.1, 0.2, 0.3, 0.1]  for "The"
  Q2 = [0.4, 0.1, 0.2, 0.3]  for "cat"
  Q3 = [0.2, 0.3, 0.1, 0.4]  for "sat"

Key vectors (same as query in self-attention):
  K1 = [0.1, 0.2, 0.3, 0.1]  for "The"
  K2 = [0.4, 0.1, 0.2, 0.3]  for "cat"
  K3 = [0.2, 0.3, 0.1, 0.4]  for "sat"

Value vectors:
  V1 = [1, 0, 0, 0]  for "The"
  V2 = [0, 1, 0, 0]  for "cat"
  V3 = [0, 0, 1, 0]  for "sat"</code></pre>
<p><strong>Computation for first query (position 0: “The”):</strong></p>
<pre><code>Step 1: Q1 @ K^T (similarity scores)
  Q1·K1 = 0.1*0.1 + 0.2*0.2 + 0.3*0.3 + 0.1*0.1 = 0.15
  Q1·K2 = 0.1*0.4 + 0.2*0.1 + 0.3*0.2 + 0.1*0.3 = 0.15
  Q1·K3 = 0.1*0.2 + 0.2*0.3 + 0.3*0.1 + 0.1*0.4 = 0.15

  Scores: [0.15, 0.15, 0.15]  (all equal - new in training)

Step 2: Divide by √d_k = √4 = 2
  [0.075, 0.075, 0.075]

Step 3: Softmax
  exp(0.075) ≈ 1.078
  exp(0.075) ≈ 1.078
  exp(0.075) ≈ 1.078

  Sum: 3.234

  Softmax: [1.078/3.234, 1.078/3.234, 1.078/3.234]
         = [0.333, 0.333, 0.333]
         (uniform distribution)

Step 4: Weight values
  0.333 * V1 + 0.333 * V2 + 0.333 * V3
  = 0.333 * [1,0,0,0] + 0.333 * [0,1,0,0] + 0.333 * [0,0,1,0]
  = [0.333, 0.333, 0.333, 0]</code></pre>
<p><strong>After training:</strong></p>
<pre><code>With learned embeddings, differences emerge:

Step 1: Q1 @ K^T
  Q1·K1 = 0.8   (high - "The" attends to itself)
  Q1·K2 = 0.2   (low - "The" doesn't attend to "cat")
  Q1·K3 = 0.3   (low - "The" doesn't attend to "sat")

Step 2: After scaling and softmax
  [0.7, 0.15, 0.15]

Step 3: Weighted values
  0.7 * V1 + 0.15 * V2 + 0.15 * V3
  = [0.7, 0.15, 0.15, 0]

  Interpretation:
  "The" mostly looks at itself
  Some information from neighboring words
  Reasonable: "The" is article, not much context needed</code></pre>
</section>
<section id="multi-head-attention" class="level3" data-number="1.3.4">
<h3 data-number="1.3.4" class="anchored" data-anchor-id="multi-head-attention"><span class="header-section-number">1.3.4</span> Multi-Head Attention</h3>
<p><strong>Why multiple heads?</strong></p>
<pre><code>Single attention head learns one type of relationship
Different heads can learn different patterns

Head 1: Syntactic (grammar)
  "verb" attends to "object"
  "noun" attends to "adjective"

Head 2: Semantic (meaning)
  "pronoun" attends to "antecedent"
  "reference" attends to "entity"

Head 3: Long-range
  "end of sentence" attends to "beginning"
  Captures discourse structure

Head 4: Word type
  Different parts of speech have different patterns

Multiple heads = multiple representation subspaces
More expressive than single head</code></pre>
<p><strong>Architecture:</strong></p>
<pre><code>Input: x (seq_len, d_model)

For each head h = 1 to num_heads:
  ① Project to query space
     Q_h = x @ W_q^(h)    (seq_len, d_k)

  ② Project to key space
     K_h = x @ W_k^(h)    (seq_len, d_k)

  ③ Project to value space
     V_h = x @ W_v^(h)    (seq_len, d_v)

  ④ Compute attention
     head_h = Attention(Q_h, K_h, V_h)  (seq_len, d_v)

Concatenate all heads:
  MultiHead = [head_1 || head_2 || ... || head_h]
              (seq_len, h*d_v)

Linear projection:
  output = MultiHead @ W_o
           (seq_len, d_model)</code></pre>
<p><strong>Example - 8 heads with d_model=512:</strong></p>
<pre><code>Each head operates in d_k = 512/8 = 64 dimensional space
8 different projection matrices per Q, K, V

Result:
  8 independent attention mechanisms
  Each learns different patterns
  Combined through concatenation and final projection

Total parameters for multi-head attention:
  Q projections: 8 × 512 × 64 = 262K
  K projections: 8 × 512 × 64 = 262K
  V projections: 8 × 512 × 64 = 262K
  Output projection: 512 × 512 = 262K
  Total: ~1M parameters per multi-head attention layer</code></pre>
</section>
<section id="scaled-dot-product-attention-revisited" class="level3" data-number="1.3.5">
<h3 data-number="1.3.5" class="anchored" data-anchor-id="scaled-dot-product-attention-revisited"><span class="header-section-number">1.3.5</span> Scaled Dot-Product Attention Revisited</h3>
<p><strong>Why scale by 1/√d_k?</strong></p>
<pre><code>Reason: Prevents gradient vanishing

Without scaling:
  For large d_k:
  Q @ K^T values become very large

  Example: Q and K each 64D
  Dot product: 64 independent terms
  Average value: 64 * (avg term)

  Large values → softmax saturates → gradients → 0

Scaling by 1/√d_k:
  Normalizes dot product variance
  Keep values in reasonable range [-1, 1] roughly
  Softmax doesn't saturate
  Gradients flow properly

Mathematical justification:
  Var(Q @ K^T) = Var(Σ q_i * k_i)
                = Σ Var(q_i * k_i)
                = d_k  (if independent)

  Std dev = √d_k

  Scaling by 1/√d_k makes std dev = 1
  Keeps gradients stable</code></pre>
</section>
</section>
<section id="transformer-encoder" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="transformer-encoder"><span class="header-section-number">1.4</span> 8.3 Transformer Encoder</h2>
<section id="architecture-overview" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="architecture-overview"><span class="header-section-number">1.4.1</span> Architecture Overview</h3>
<pre><code>Input sequence
    ↓
Embedding + Positional Encoding
    ↓
┌─────────────────────────────┐
│  Transformer Encoder Layer  │ ×N (typically 12)
│  ┌────────────────────────┐ │
│  │ Multi-Head Attention   │ │
│  └────────┬───────────────┘ │
│           ↓                  │
│  ┌─────────────────────────┐ │
│  │ Add &amp; Normalize         │ │
│  └────────┬────────────────┘ │
│           ↓                  │
│  ┌─────────────────────────┐ │
│  │ Feed-Forward Network    │ │
│  │ (2 linear layers, ReLU) │ │
│  └────────┬────────────────┘ │
│           ↓                  │
│  ┌─────────────────────────┐ │
│  │ Add &amp; Normalize         │ │
│  └────────┬────────────────┘ │
└─────────────────────────────┘
    ↓
Output (same shape as input)</code></pre>
</section>
<section id="detailed-layer-breakdown" class="level3" data-number="1.4.2">
<h3 data-number="1.4.2" class="anchored" data-anchor-id="detailed-layer-breakdown"><span class="header-section-number">1.4.2</span> Detailed Layer Breakdown</h3>
<p><strong>1. Positional Encoding</strong></p>
<pre><code>Problem: Self-attention is permutation invariant
  Meaning: Word order doesn't matter!

  Attention doesn't care about position
  Just about content similarity

  Example:
    "dog bites man" vs "man bites dog"
    Same words, different meaning
    But attention treats them the same!

Solution: Add position information

Sinusoidal encoding:
  PE(pos, 2i) = sin(pos / 10000^(2i/d_model))
  PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))

  Where:
    pos = position in sequence (0, 1, 2, ...)
    i = dimension index (0, 1, 2, ..., d_model/2)

Example: Position 0, dimension 0
  PE(0, 0) = sin(0) = 0

  Position 1, dimension 0:
  PE(1, 0) = sin(1 / 10000^0) = sin(1) ≈ 0.84

Properties:
  ① Different positions have different encodings
  ② Patterns repeat at different frequencies
  ③ Model can learn relative positions
  ④ Can extrapolate to longer sequences than training</code></pre>
<p><strong>2. Multi-Head Self-Attention</strong></p>
<pre><code>All positions attend to all positions
8-12 heads typically
Each head learns different patterns

Output same shape as input</code></pre>
<p><strong>3. Add &amp; Normalize (Residual Connection + Layer Normalization)</strong></p>
<pre><code>Residual connection:
  output = attention_output + input

  Why?
  ① Preserves original information
  ② Enables deep networks (gradient flows directly)
  ③ Output can learn "residual" (difference)

Layer Normalization:
  Normalize across feature dimension

  mean = mean(x along d_model dimension)
  variance = var(x along d_model dimension)
  normalized = (x - mean) / sqrt(variance + epsilon)
  output = γ * normalized + β

  γ, β are learnable parameters

  Why LN instead of Batch Norm?
  ① Batch norm depends on batch statistics
     Different at train/test time

  ② Layer norm is deterministic
     Doesn't depend on batch
     Same at train/test

  ③ Works better for sequences</code></pre>
<p><strong>4. Feed-Forward Network</strong></p>
<pre><code>MLP with 2 layers and ReLU:

FFN(x) = Linear2(ReLU(Linear1(x)))

Dimensions:
  Linear1: d_model → d_ff (usually 4*d_model)
  ReLU: d_ff → d_ff
  Linear2: d_ff → d_model

Example with d_model = 512:
  Linear1: 512 → 2048
  ReLU: 2048 → 2048
  Linear2: 2048 → 512

Why expand then contract?
  ① Increases non-linearity
  ② More expressive intermediate representation
  ③ Standard in deep learning</code></pre>
</section>
<section id="full-transformer-encoder" class="level3" data-number="1.4.3">
<h3 data-number="1.4.3" class="anchored" data-anchor-id="full-transformer-encoder"><span class="header-section-number">1.4.3</span> Full Transformer Encoder</h3>
<p><strong>BERT (Bidirectional Encoder Representations from Transformers):</strong></p>
<pre><code>Architecture:
  ① Input: Tokens or subword units

  ② Embeddings:
     - Token embedding (word id → vector)
     - Positional embedding (position → vector)
     - Segment embedding (which sentence)
     - Sum all three

  ③ 12 layers (BERT-base) or 24 (BERT-large) of:
     - Multi-head attention (8-12 heads)
     - Feed-forward network
     - Residual connections + Layer norm

  ④ Output: Contextual embedding for each token

Example input: "The cat sat on the mat"

Processing:
  [CLS] The cat sat on the mat [SEP]
    ↓
  Embed each token
    ↓
  Add positional info
    ↓
  Layer 1:
    All tokens attend to all tokens
    Self-attention with 12 different heads

    "The" attends to: "The" (self), "cat", "sat", "on", "the", "mat"
    Different heads pay attention to different words
    Results concatenated

    Feed-forward applied to each position
    Residual + Layer norm

  Layer 2-12:
    Same process, but input is output from previous layer
    Further refinement

Output:
  12 vectors for each token
  Plus one special [CLS] token representing full sequence</code></pre>
</section>
</section>
<section id="transformer-decoder" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="transformer-decoder"><span class="header-section-number">1.5</span> 8.4 Transformer Decoder</h2>
<section id="causal-masking" class="level3" data-number="1.5.1">
<h3 data-number="1.5.1" class="anchored" data-anchor-id="causal-masking"><span class="header-section-number">1.5.1</span> Causal Masking</h3>
<p><strong>Problem:</strong></p>
<pre><code>During inference, generate one token at a time:
  Step 1: Predict token 1 (no prior tokens)
  Step 2: Predict token 2 (given token 1)
  Step 3: Predict token 3 (given tokens 1, 2)

During training (teacher forcing):
  Complete sequence available: token 1, 2, 3, 4, 5

To prepare model for inference:
  Hide future tokens during training

Mechanism: Causal mask</code></pre>
<p><strong>Causal mask visualization:</strong></p>
<pre><code>Attention positions (what can attend to what):

Sequence: [token_1, token_2, token_3, token_4, token_5]

Position 1 (token_1):
  Can attend to: position 1
  Cannot attend to: positions 2, 3, 4, 5

Position 2 (token_2):
  Can attend to: positions 1, 2
  Cannot attend to: positions 3, 4, 5

Position 3 (token_3):
  Can attend to: positions 1, 2, 3
  Cannot attend to: positions 4, 5

Attention matrix (✓ = can attend, ✗ = masked):

       pos1  pos2  pos3  pos4  pos5
pos1    ✓     ✗     ✗     ✗     ✗
pos2    ✓     ✓     ✗     ✗     ✗
pos3    ✓     ✓     ✓     ✗     ✗
pos4    ✓     ✓     ✓     ✓     ✗
pos5    ✓     ✓     ✓     ✓     ✓

Mask implementation:
  Before softmax, set masked positions to -∞
  softmax(-∞) = 0
  Effect: Attention weight = 0 for masked positions</code></pre>
</section>
<section id="autoregressive-generation" class="level3" data-number="1.5.2">
<h3 data-number="1.5.2" class="anchored" data-anchor-id="autoregressive-generation"><span class="header-section-number">1.5.2</span> Autoregressive Generation</h3>
<p><strong>Process:</strong></p>
<pre><code>① Start: Input special token [START]
         Decoder produces distribution over vocabulary

② Step 1: Sample/select token with highest probability
          Let's say we get "A"

③ Step 2: Input "[START] A"
          Decoder predicts next token
          Get "red"

④ Step 3: Input "[START] A red"
          Decoder predicts next token
          Get "cat"

⑤ Continue until [END] token or max length

Generated: "A red cat"</code></pre>
<p><strong>Key points:</strong></p>
<pre><code>① Causal masking ensures only past tokens visible
② Gradual refinement of representation
③ Can use greedy (highest probability) or sampling
④ Sampling: More diverse but less controlled
   Greedy: More consistent but can repeat</code></pre>
</section>
<section id="cross-attention-in-decoder" class="level3" data-number="1.5.3">
<h3 data-number="1.5.3" class="anchored" data-anchor-id="cross-attention-in-decoder"><span class="header-section-number">1.5.3</span> Cross-Attention in Decoder</h3>
<p><strong>Integration with encoder:</strong></p>
<pre><code>Encoder processes source:
  e.g., Image encoded to 196 patch embeddings

Decoder:
  ① Self-attention: Decoder attends to previously generated tokens
  ② Cross-attention: Decoder attends to encoder output
  ③ Feed-forward

Cross-attention details:
  Query: Current decoder hidden state
  Key/Value: Encoder output

  Result: Decoder can look at source modality
          Ground generation in input</code></pre>
<p><strong>Example - Image captioning:</strong></p>
<pre><code>Image: [Cat photo]
       ↓
Image encoder: 196 patch embeddings

Decoder generating caption:

Step 1:
  Decoder input: [START]
  Self-attention: Only [START], attends to itself
  Cross-attention: [START] attends to all 196 patches
                   "What's in image?"
  Output: Probability distribution for first word

Step 2:
  Decoder input: [START] A
  Self-attention: "A" attends to [START] and itself
                  "What context?"
  Cross-attention: "A" attends to patches
                   "What modifies 'A'?"
  Output: "cat"

Step 3:
  Decoder input: [START] A cat
  Self-attention: "cat" attends to [START], "A", "cat"
  Cross-attention: "cat" attends to patches
                   "What object is this?"
  Output: "sitting"

...

Caption: "A cat sitting on a couch"</code></pre>
</section>
</section>
<section id="putting-it-together-vision-transformer-vit" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="putting-it-together-vision-transformer-vit"><span class="header-section-number">1.6</span> 8.5 Putting it Together: Vision Transformer (ViT)</h2>
<section id="architecture-for-images" class="level3" data-number="1.6.1">
<h3 data-number="1.6.1" class="anchored" data-anchor-id="architecture-for-images"><span class="header-section-number">1.6.1</span> Architecture for Images</h3>
<pre><code>Image (224×224×3)
    ↓
Divide into patches (16×16)
    ↓
14 × 14 = 196 patches
    ↓
Each patch: 16×16×3 = 768D
    ↓
Linear projection: 768D → 768D embedding
    ↓
Add [CLS] special token
    ↓
Positional encoding (196 + 1 positions)
    ↓
Concatenate: [[CLS]; patch_1; patch_2; ...; patch_196]
             (197 tokens of 768D each)
    ↓
Transformer encoder (12 layers):
  Multi-head attention (12 heads)
  Feed-forward (3072D intermediate)
  Residual connections + Layer norm
    ↓
Extract [CLS] token representation
    ↓
Linear classifier: 768D → num_classes
    ↓
Output: Class probabilities</code></pre>
</section>
<section id="why-vit-works" class="level3" data-number="1.6.2">
<h3 data-number="1.6.2" class="anchored" data-anchor-id="why-vit-works"><span class="header-section-number">1.6.2</span> Why ViT Works</h3>
<pre><code>Key insight 1: Patches as tokens
  Images have spatial structure
  Patches preserve local information
  Transformer learns global relationships

Key insight 2: Transformer is universal
  Can process any sequence of tokens
  Doesn't care if tokens are image or text
  Same architecture works for both!

Key insight 3: Attention gives global context
  CNNs need many layers for global receptive field
  ViT has global attention from layer 1
  Enables fast learning

Empirical finding:
  With small data: CNN &gt;&gt; ViT
  With large data: ViT &gt;&gt; CNN

  Trade-off: Inductive bias vs expressive power
  CNN: Strong inductive bias (local structure)
       Works with limited data
  ViT: Weak inductive bias
       Needs large data to learn structure</code></pre>
</section>
</section>
<section id="key-takeaways" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="key-takeaways"><span class="header-section-number">1.7</span> Key Takeaways</h2>
<ul>
<li><strong>Transformers</strong> solve sequential bottleneck through attention</li>
<li><strong>Self-attention</strong> computes context through similarity</li>
<li><strong>Multi-head attention</strong> learns diverse patterns</li>
<li><strong>Positional encoding</strong> preserves sequence order</li>
<li><strong>Residual connections</strong> enable deep networks</li>
<li><strong>Feed-forward networks</strong> add non-linearity</li>
<li><strong>Causal masking</strong> enables autoregressive generation</li>
<li><strong>Cross-attention</strong> connects source and target</li>
<li><strong>Vision Transformer</strong> shows transformers work for images too</li>
</ul>
</section>
<section id="exercises" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="exercises"><span class="header-section-number">1.8</span> Exercises</h2>
<p><strong>⭐ Beginner:</strong> 1. Compute self-attention by hand 2. Understand causal masking 3. Visualize positional encoding patterns</p>
<p><strong>⭐⭐ Intermediate:</strong> 4. Implement multi-head attention from scratch 5. Build simple transformer encoder 6. Visualize attention patterns</p>
<p><strong>⭐⭐⭐ Advanced:</strong> 7. Implement full transformer encoder-decoder 8. Build Vision Transformer 9. Implement efficient attention variants</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>© 2024 Kai Guo - Multimodal Learning Guide</p>
</div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>