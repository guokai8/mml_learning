# Requirements for Multimodal Learning Jupyter Notebooks
# Author: Kai Guo (guokai8@gmail.com)

# Core ML libraries
torch>=1.9.0
torchvision>=0.10.0
torchaudio>=0.9.0
transformers>=4.20.0
datasets>=2.0.0

# Scientific computing
numpy>=1.21.0
scipy>=1.7.0
scikit-learn>=1.0.0
pandas>=1.3.0

# Visualization
matplotlib>=3.4.0
seaborn>=0.11.0
plotly>=5.0.0
ipywidgets>=7.6.0

# Image processing
Pillow>=8.3.0
opencv-python>=4.5.0

# NLP libraries
nltk>=3.6.0
spacy>=3.4.0
sentence-transformers>=2.2.0

# Specialized multimodal libraries
clip-by-openai>=1.0
open-clip-torch>=2.0.0

# Jupyter ecosystem
jupyter>=1.0.0
jupyterlab>=3.0.0
notebook>=6.4.0
ipykernel>=6.0.0

# Utilities
requests>=2.25.0
tqdm>=4.62.0
wandb>=0.12.0  # For experiment tracking (optional)

# Audio processing
librosa>=0.8.0
soundfile>=0.10.0

# Additional ML utilities
einops>=0.4.0  # For tensor operations
timm>=0.6.0    # Image models
ftfy>=6.1.0    # Text processing for CLIP

# Development tools (optional)
black>=22.0.0
flake8>=4.0.0
pytest>=7.0.0
