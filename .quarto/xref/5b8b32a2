{"entries":[],"headings":["chapter-10-seminal-models-and-architectures","learning-objectives","clip-learning-transferable-models-from-natural-language-supervision","revolution-in-vision-understanding","clip-architecture","zero-shot-transfer","benchmark-results","impact-on-field","blip-2-bootstrapping-language-image-pre-training-with-frozen-image-encoders","context-and-motivation","blip-2-architecture","why-it-works","blip-2-capabilities","benchmark-results-1","gpt-4v-multimodal-reasoning","revolutionary-capabilities","examples-of-capabilities","architecture-inferred","capabilities-and-limitations","usage-and-access","practical-usage-example","vision-transformers-vit","architecture-deep-dive","vit-variants","training-vit","why-vit-works","comparison-and-selection-guide","performance-comparison","choosing-between-models","model-selection-guide","hybrid-approaches","key-takeaways","exercises"]}